{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SVM Training â€“ Class Weighted Approach\n",
        "\n",
        "This notebook contains:\n",
        "\n",
        "*   Data preprocessing\n",
        "* Class imbalance handling\n",
        "* Model training\n",
        "* Evaluation metrics\n",
        "* Confusion matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "on7LelhnWRAh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWX359E2Qdtm"
      },
      "outputs": [],
      "source": [
        "!pip install -q scikit-learn pandas numpy matplotlib seaborn joblib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"clean_amazon_reviews.csv\")\n",
        "print(\"\\nDataset shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "df = df[['clean_review', 'sentiment']].dropna().reset_index(drop=True)\n",
        "\n",
        "print(f\"\\nCleaned dataset shape: {df.shape}\")\n",
        "print(\"\\nOriginal sentiment distribution:\")\n",
        "sentiment_counts = df['sentiment'].value_counts()\n",
        "print(sentiment_counts)\n",
        "print(f\"\\nClass distribution percentages:\")\n",
        "for label, count in sentiment_counts.items():\n",
        "    print(f\"  {label}: {count} ({count/len(df)*100:.1f}%)\")\n",
        "\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['sentiment'])\n",
        "\n",
        "label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
        "print(f\"\\nLabel mapping: {label_mapping}\")\n",
        "\n",
        "\n",
        "class_weights = compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=np.unique(df['label']),\n",
        "    y=df['label']\n",
        ")\n",
        "\n",
        "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
        "print(f\"\\nCalculated class weights: {class_weight_dict}\")\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_review'],\n",
        "    df['label'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain samples: {len(X_train)}\")\n",
        "print(f\"Test samples: {len(X_test)}\")\n",
        "\n",
        "train_dist = pd.Series(y_train).value_counts().sort_index()\n",
        "test_dist = pd.Series(y_test).value_counts().sort_index()\n",
        "print(f\"\\nTrain distribution: {train_dist.to_dict()}\")\n",
        "print(f\"Test distribution: {test_dist.to_dict()}\")\n",
        "\n",
        "\n",
        "print(\"\\nðŸ”„ Vectorizing text data with TF-IDF...\")\n",
        "\n",
        "tfidf = TfidfVectorizer(\n",
        "    max_features=15000,\n",
        "    ngram_range=(1, 2),\n",
        "    min_df=5,\n",
        "    max_df=0.8,\n",
        "    sublinear_tf=True\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(f\"TF-IDF shape: {X_train_tfidf.shape}\")\n",
        "print(f\"Vocabulary size: {len(tfidf.vocabulary_)}\")\n",
        "\n",
        "\n",
        "print(\"\\nðŸš€ Training SVM with GridSearchCV and class weights...\")\n",
        "\n",
        "param_grid = {\n",
        "    \"C\": [0.1, 1, 10],\n",
        "    \"max_iter\": [2000, 5000]\n",
        "}\n",
        "\n",
        "base_svm = LinearSVC(\n",
        "    class_weight='balanced',\n",
        "    random_state=42,\n",
        "    dual=False\n",
        ")\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    base_svm,\n",
        "    param_grid,\n",
        "    cv=3,\n",
        "    scoring='f1_weighted',\n",
        "    n_jobs=-1,\n",
        "    verbose=2\n",
        ")\n",
        "\n",
        "grid.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print(f\"\\nâœ… Best parameters: {grid.best_params_}\")\n",
        "print(f\"Best cross-validation F1 score: {grid.best_score_:.4f}\")\n",
        "\n",
        "best_svm = grid.best_estimator_\n",
        "\n",
        "\n",
        "print(\"\\nðŸ”§ Calibrating SVM for probability estimates...\")\n",
        "\n",
        "calibrated_svm = CalibratedClassifierCV(\n",
        "    best_svm,\n",
        "    method='sigmoid',\n",
        "    cv=3\n",
        ")\n",
        "\n",
        "calibrated_svm.fit(X_train_tfidf, y_train)\n",
        "print(\"âœ… Calibration complete!\")\n",
        "\n",
        "\n",
        "print(\"\\nðŸ“Š Evaluating model on test set...\")\n",
        "\n",
        "y_pred = calibrated_svm.predict(X_test_tfidf)\n",
        "y_pred_proba = calibrated_svm.predict_proba(X_test_tfidf)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1_weighted = f1_score(y_test, y_pred, average='weighted')\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"\\nTest Set Metrics:\")\n",
        "print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "print(f\"  F1 (weighted): {f1_weighted:.4f}\")\n",
        "print(f\"  F1 (macro): {f1_macro:.4f}\")\n",
        "print(f\"  Precision: {precision:.4f}\")\n",
        "print(f\"  Recall: {recall:.4f}\")\n",
        "\n",
        "y_true_labels = le.inverse_transform(y_test)\n",
        "y_pred_labels = le.inverse_transform(y_pred)\n",
        "\n",
        "print(\"\\nðŸ“‹ Detailed Classification Report:\")\n",
        "print(classification_report(y_true_labels, y_pred_labels, target_names=le.classes_))\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=le.classes_)\n",
        "df_cm = pd.DataFrame(cm, index=le.classes_, columns=le.classes_)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar_kws={'label': 'Count'})\n",
        "plt.title(\"Confusion Matrix - SVM Class Weighted Model\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"\\nðŸ“ˆ Top predictive features per class:\")\n",
        "\n",
        "feature_names = np.array(tfidf.get_feature_names_out())\n",
        "\n",
        "if hasattr(best_svm, 'coef_'):\n",
        "    coef = best_svm.coef_\n",
        "\n",
        "    for idx, class_name in enumerate(le.classes_):\n",
        "        print(f\"\\n{class_name.upper()}:\")\n",
        "        top_indices = np.argsort(coef[idx])[-10:][::-1]\n",
        "        top_features = feature_names[top_indices]\n",
        "        top_scores = coef[idx][top_indices]\n",
        "\n",
        "        for feature, score in zip(top_features, top_scores):\n",
        "            print(f\"  {feature}: {score:.4f}\")\n",
        "\n",
        "\n",
        "print(\"\\nðŸ’¾ Saving model and components...\")\n",
        "model_save_path = \"svm_sentiment_weighted\"\n",
        "os.makedirs(model_save_path, exist_ok=True)\n",
        "\n",
        "joblib.dump(calibrated_svm, f\"{model_save_path}/svm_model.pkl\")\n",
        "joblib.dump(tfidf, f\"{model_save_path}/tfidf.pkl\")\n",
        "joblib.dump(le, f\"{model_save_path}/label_encoder.pkl\")\n",
        "\n",
        "metadata = {\n",
        "    'class_weights': class_weight_dict,\n",
        "    'label_mapping': label_mapping,\n",
        "    'num_classes': len(le.classes_),\n",
        "    'classes': le.classes_.tolist(),\n",
        "    'best_params': grid.best_params_,\n",
        "    'vocabulary_size': len(tfidf.vocabulary_),\n",
        "    'test_accuracy': accuracy,\n",
        "    'test_f1': f1_weighted\n",
        "}\n",
        "joblib.dump(metadata, f\"{model_save_path}/model_metadata.pkl\")\n",
        "\n",
        "print(\"âœ… Model saved successfully!\")\n",
        "\n",
        "!zip -r svm_sentiment_weighted.zip svm_sentiment_weighted\n",
        "\n",
        "print(\"ðŸ“¥ Downloading model...\")\n",
        "files.download(\"svm_sentiment_weighted.zip\")\n",
        "\n",
        "\n",
        "class SVMSentimentPredictor:\n",
        "    def __init__(self, model_path=\"svm_sentiment_weighted\"):\n",
        "\n",
        "        self.model = joblib.load(f\"{model_path}/svm_model.pkl\")\n",
        "        self.tfidf = joblib.load(f\"{model_path}/tfidf.pkl\")\n",
        "        self.label_encoder = joblib.load(f\"{model_path}/label_encoder.pkl\")\n",
        "        self.metadata = joblib.load(f\"{model_path}/model_metadata.pkl\")\n",
        "\n",
        "        print(f\"âœ… SVM Sentiment predictor loaded successfully!\")\n",
        "        print(f\"   Classes: {self.metadata['classes']}\")\n",
        "\n",
        "    def predict(self, texts):\n",
        "        if isinstance(texts, str):\n",
        "            texts = [texts]\n",
        "\n",
        "        X_vec = self.tfidf.transform(texts)\n",
        "\n",
        "        preds = self.model.predict(X_vec)\n",
        "        probs = self.model.predict_proba(X_vec)\n",
        "\n",
        "        labels = self.label_encoder.inverse_transform(preds)\n",
        "\n",
        "        results = []\n",
        "        for i, text in enumerate(texts):\n",
        "            prob_dict = {\n",
        "                label: float(probs[i][idx])\n",
        "                for idx, label in enumerate(self.label_encoder.classes_)\n",
        "            }\n",
        "\n",
        "            results.append({\n",
        "                \"text\": text,\n",
        "                \"predicted_label\": labels[i],\n",
        "                \"confidence\": float(np.max(probs[i])),\n",
        "                \"probabilities\": prob_dict\n",
        "            })\n",
        "\n",
        "        return results[0] if len(texts) == 1 else results\n",
        "\n",
        "predictor = SVMSentimentPredictor()\n",
        "\n",
        "\n",
        "print(\"\\nðŸ§ª Testing the trained SVM model:\")\n",
        "\n",
        "test_cases = [\n",
        "    \"This product is amazing and works perfectly!\",\n",
        "    \"Worst purchase ever, totally disappointed\",\n",
        "    \"Quality is okay, nothing special\",\n",
        "    \"The quality was bad but delivery was okay\",\n",
        "    \"Excellent service and fast shipping\",\n",
        "    \"Not worth the money, poor quality\"\n",
        "]\n",
        "\n",
        "print(\"\\nSingle predictions:\")\n",
        "for text in test_cases:\n",
        "    result = predictor.predict(text)\n",
        "    print(f\"Text: '{text}'\")\n",
        "    print(f\"Prediction: {result['predicted_label']} (confidence: {result['confidence']:.3f})\")\n",
        "    print(f\"Probabilities: {result['probabilities']}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"\\nBatch prediction:\")\n",
        "batch_results = predictor.predict(test_cases)\n",
        "for result in batch_results:\n",
        "    print(f\"{result['predicted_label']}: {result['text']}\")\n",
        "\n",
        "print(\"\\nðŸŽ‰ Complete! Your optimized SVM class-weighted sentiment model is ready!\")\n"
      ]
    }
  ]
}